# -*- coding: utf-8 -*-
"""LVADSUSR131_Vinay_FA_LAB2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZUxai85DRgRYHayY934r6brr3Wfc4dh9
"""

#Regression

#import libraries
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
from sklearn import linear_model
import matplotlib.pyplot as plt
df = pd.read_csv('/content/auto-mpg.csv')
df.head()

df.info()

#some null value so we will use a function to fill the null value
df.isnull().sum()
df = df.fillna(method='ffill')

plt.boxplot(df['displacement'])

plt.boxplot(df['weight'])

plt.xlabel('mpg')
plt.ylabel('displacement')
plt.scatter(df.mpg,df.displacement,color='red',marker='*')

X = df.drop(['car name','mpg','origin','model year','horsepower'],axis='columns')

y = df.mpg
#use train test split
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.3)

model=linear_model.LinearRegression()

model.fit(X_train,y_train)

predictions=model.predict(X_test)
print(predictions)

#use metrics
from sklearn.metrics import mean_squared_error,mean_absolute_error
import numpy as np


print("MEan_squared_error")
print(mean_squared_error(predictions,y_test))
print('\n')
print("Mean absolute error")
print(mean_absolute_error(predictions,y_test))
print('\n')
print("Root Mean squared error :")
print(np.sqrt(mean_squared_error(predictions,y_test)))

import numpy as np
import pandas as pd
df=pd.read_csv('/content/auto-mpg.csv')
df

#2
#Data Pre-Processing
df.isnull().sum()

#df.dropna()
#to remove duplicates which is not needed here as there are no null values

df=df.fillna(df.mean())

df.isnull().sum()

#Outliers
import matplotlib.pyplot as plt
plt.boxplot(df['weight'])
plt.boxplot(df)

#removing Outliers
Q1 = np.percentile(df, 25, axis=0)
Q3 = np.percentile(df, 75, axis=0)
Q1 = np.percentile(df, 25, axis=0)
Q3 = np.percentile(df, 75, axis=0)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
outliers_lower = (df < lower_bound).any(axis=1)
outliers_upper = (df > upper_bound).any(axis=1)
outliers = outliers_lower | outliers_upper
df1 = df[~outliers]

#3
#Exploratory Data Analysis
df.info()

df.describe()

df.head(5)

df.corr()

df.shape

#4
#Model Training and Tesing
#feature selection
import seaborn as sns
sns.heatmap(df.corr())

df

x=df[['cylinders','displacement','weight','acceleration']]
y=df['mpg']

#split dataset
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)

from sklearn.linear_model import LinearRegression
lr=LinearRegression()
lr.fit(x_train,y_train)
y_pred=lr.predict(x_test)

#Model evaluation Metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
acc=f1_score(y_pred,y_test)
acc1=accuracy_score(y_pred,y_test)
print(acc,acc1)